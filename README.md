# ğŸ“˜ Sentiment Analysis on IMDB Movie Reviews using RNN

This project implements a Recurrent Neural Network (RNN) based sentiment analysis model trained on the IMDB Movie Reviews Dataset.
It classifies movie reviews as Positive or Negative using sequential deep learning architectures such as Simple RNN, GRU, and LSTM.

The repository contains:

RNN_Project_1_Sentiment_Analysis.ipynb â€” full workflow (preprocessing, training, evaluation, visualization)

imdb_lstm_model.pth â€” final trained LSTM model

# ğŸ“ Project Folder Structure
# ğŸ“¦ Sentiment-Analysis-RNN
â”‚
# â”œâ”€â”€ RNN_Project_1_Sentiment_Analysis.ipynb   # Contains all training steps, preprocessing, evaluation
â”‚
# â”œâ”€â”€ imdb_lstm_model.pth                      # Saved trained LSTM model
â”‚
# â””â”€â”€ README.md                                # Documentation

## ğŸ“ Problem Statement

Build a deep learning model using Recurrent Neural Networks (RNNs) to classify the sentiment of IMDB movie reviews as:

0 â†’ Negative

1 â†’ Positive

The objective is to learn sequential dependencies in text data to improve sentiment classification performance.

## ğŸ“‚ Dataset Overview

- Source: IMDB Large Movie Review Dataset (Hugging Face datasets)

- Total Samples: 50,000

- Training: 25,000

- Testing: 25,000

- Labels: Binary sentiment

Each sample consists of a complete movie review and its sentiment label.

# ğŸ§  Approach & Workflow
- âœ” Data Preprocessing

- Tokenization

- Vocabulary building

Padding sequences to uniform length

# âœ” Model Architecture

- Implemented Models: Simple RNN, GRU, LSTM

- Loss Function: CrossEntropy Loss

- Metrics: Accuracy, Precision, Recall, F1-score

- Visualization:

- Accuracy vs Epochs

- Loss vs Epochs

- Confusion Matrix

# âœ” Training Output

- LSTM achieved the best performance: 85.26% validation accuracy

- Other models (Simple RNN, GRU, LSTM + GloVe) achieved ~50%, indicating near-random learning

# ğŸ“Œ Key Insights & Conclusions

- LSTM outperformed all other architectures by a significant margin.

- The vocabulary was very large (40,133 tokens) due to minimal preprocessing.

- GloVe embeddings performed poorly because of a large vocabulary mismatch (17,000+ missing words).

- Models exhibited unstable learning patterns, suggesting noisy preprocessing.

- Training was limited to 15 epochs, preventing full convergence.

# âš ï¸ Technical Limitations

- Minimal preprocessing (HTML tags, stopwords, punctuation retained).

- Very large vocabulary increased sparsity and memory usage.

- Deeper architectures underperformed due to limited epochs.

- Minimal hyperparameter tuning reduced optimization quality.

# ğŸš€ Future Improvements
## ğŸ”§ Preprocessing Enhancements

- Remove HTML tags

- Apply lemmatization or stemming

- Remove stopwords & punctuation

# ğŸ§  Vocabulary Optimization

- Increase minimum frequency threshold

- Use subword/BPE tokenization

- Limit vocabulary to top-k most frequent words

# ğŸ— Model Enhancements

- Bidirectional GRU/LSTM

- Add attention mechanisms

- Use multi-layer LSTMs with dropout and batch normalization

# ğŸ§ª Training Improvements

- Learning rate scheduling

- Gradient clipping

- More epochs + early stopping

- Use AdamW or RMSprop optimizers

# ğŸ“š Embedding Improvements

- Use domain-specific embeddings

- Improve handling of unknown tokens

- Try contextual embeddings (e.g., BERT, RoBERTa)
